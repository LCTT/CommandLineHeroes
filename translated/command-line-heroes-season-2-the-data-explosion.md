[#]: collector: (bestony)
[#]: translator: (TimeBear)
[#]: reviewer: ( )
[#]: publisher: ( )
[#]: url: ( )
[#]: subject: (Command Line Heroes: Season 2: The Data Explosion)
[#]: via: (https://www.redhat.com/en/command-line-heroes/season-2/the-data-explosion)
[#]: author: (RedHat https://www.redhat.com/en/command-line-heroes)

《代码英雄》第二季：数据爆炸
======
**00:03** - _Saron Yitbarek_

如果你把从人类历史早期到2003年创建的所有人类数据计算在内，你将得到大约500万GB的数据。我们昨天创建了多少GB的数据？

**00:15** - _Poll response 1_

哦，天哪，10万GB的数据。

**00:21** -_Poll response 2_

可能是500万GB数据。

**00:23** - _Poll response 3_

我们在昨天一天之内创建了多少GB的数据？1000万GB数据？

**00:31** - _Poll response 4_

我会说，我不知道，可能是200万GB数据？

**00:36** - _Poll response 5_

可能是100万GB数据一天？

**00:40** - _Saron Yitbarek_

回答？超过25亿GB数据。

**00:44** - _Poll response 1_

哦哇哦。

**00:44** - _Poll response 2_

25亿GB数据？

**00:45** - _Poll response 3_

所以，我们已经打破了世界纪录。

**00:45** - _Poll response 4_

那是很多GB的数据。

**00:45** - _Poll response 5_

我都不敢相信那有这么多的数据。

**00:52** - _Saron Yitbarek_

在2016年，我们的年度在线数据流量首次超过了1ZB的数据。准确的说是有1千的七乘方的比特数据。好，记住那个数字了吗？现在乘以3倍那个数字，因为那是我们将在2021年拥有的数据量大小。

**01:10** - _Saron Yitbarek_

我知道，大脑不是以ZB为单位进行思考，而只要抓住一下这一小小的事实。 我们的IP流量将在五年内翻三番。 这是数据洪流，而我们正处于其中。

**01:24** - _Saron Yitbarek_

在刚过去的一分钟里，人们发出了1600万条短信，在我说出这句话的时间里，谷歌处理了20万条搜索。

**01:37** - _Saron Yitbarek_

如果我们能在数据洪流来临时做好准备站稳脚跟，那么隐藏在数据洪流中的模式，答案和秘密可以极大地改善我们的生活。

**01:50** - _Saron Yitbarek_

我是 Saron Yitbarek，你这里是《代码英雄》，一款红帽公司原创的播客节目。潮汐即将来临。这里是第二季的第六集，数据洪流。

**02:17** - _Saron Yitbarek_

我们如何处理如此大量的数据？ 一旦采集到数据，我们将如何利用它们？ 大数据将解决我们一些最复杂的问题：

**02:29** - _Saron Yitbarek_

我们如何管理交通。我们如何种植粮食。我们如何向需要的人提供物资。但只有当我们想出如何处理这些数据，如何以最快的速度处理这些数据时，我们才能做到这一点。

**02:43** - _Kenneth Cukier_

通过获取更多的数据，我们可以用前所未有的方式来深入了解这些子组、这些细节。

**02:53** - _Saron Yitbarek_

Kenneth Cukier是《经济学人》的高级编辑，他也是他们科技播客《Babbage》的Saron Yitbarek。

**03:01** - _Kenneth Cukier_

这并不是说我们以前无法收集数据。我们可以，但这真的，真的很昂贵。真正的革命是我们可以很容易地收集这些数据。

**03:10** - _Kenneth Cukier_

现在收集数据的价格非常便宜，而且处理方式也超级简单，因为都是由电脑完成的。这已经成为我们这个时代的巨大革命，它可能是现代生活中最具有决定性的方面，在未来几十年甚至下个世纪都会如此。这也是为什么大数据如此重要的原因。

**03:33** - _Saron Yitbarek_

这段历史提醒我们到这种变化是翻天覆地的。想想看，4000年前，我们把所有的数据都刻在了干泥板上。

**03:46** - _Kenneth Cukier_

这些黏土盘很重。黏土盘烘焙后，刻在其中的数据就无法更改。所有这些信息的处理、存储、传输、创建方式的特点都发生了变化，对吗？

**04:04** - _Saron Yitbarek_

这发生了巨大的变化。大约在1450年，印刷机的发明带来了第一次信息革命。今天，我们有了自己的革命。

**04:16** - _Kenneth Cukier_

现在的信息存储介质很轻巧。信息的修改变的超级简单，无论是磁带还是电子晶体管和处理器的变革，我们只需要使用删除键就能改变我们所拥有的信息实例。我们可以以光速传输数据，不用像你说的那样携带粘土圆盘。

**04:37** - _Saron Yitbarek_

15世纪启蒙运动的大量数据在印刷机的传播下提升了我们对事物的认识。

**04:45** - _Saron Yitbarek_

今天，大数据可以再次提升我们的水平。但前提是我们要想办法利用这些数据。只有当我们建造大坝和涡轮机，才能把洪水治理好。

**05:00** - _Kenneth Cukier_

公司和个人及组织所做的事情之间可能存在着巨大的差距。这一点非常重要，因为我们已经看到，数据中有这种潜在的价值，而且收集、存储和处理数据的成本已经大大降低到一百年前甚至十年前的水平。

**05:22** - _Kenneth Cukier_

这真令人兴奋。但问题是，我们还没有在文化上，在我们的组织流程中，甚至在我们的首席财务官和首席信息官分配给数据的预算中做到这一点。

**05:35** - _Saron Yitbarek_

当你想到它的时候，就会非常沮丧。启蒙在敲门却无人应答。不过我们不回答的部分原因是，门后到底是谁？这些数据能带来什么？

**05:51** - _Saron Yitbarek_

Kenneth认为，大数据的新奇让一些公司无法实现这一飞跃。

**05:56** - _Kenneth Cukier_

收集大量数据后，这些数据的价值是什么？最诚实的答案是，如果你认为你知道，你就是个傻瓜。因为你永远无法确定今天我们将如何将数据用于明天的用途。

**06:12** - _Kenneth Cukier_

最重要的是拥有数据，并以开放的思想对待所有可以使用的方式。

**06:18** - _Saron Yitbarek_

我们将对可能发生事情的态度发生全面转变，如果按照Kenneth所设想的那样，我们把大数据做好。在这个世界上，每个人，不仅仅是数据科学家，都能发现潜力并获得洞察力。

**06:33** - _Kenneth Cukier_

通过理解这个世界，我们可以收集关于它的经验证据来理解它，为了改变它，改善它，并且可以以一种自动化的方式进行改善，我们将以不同的方式来看待这个世界，我认为这就是现在世界各地的政策制定者和商业人士以及星巴克咖啡师在文化或心理上发生的真正有趣的变化。

**07:00** - _Kenneth Cukier_

各行各业的人都有数据基因。他们明白了。他们就像接种了这种疫苗一样，现在，无论他们到哪里，他们都以数据思维方式思考。

**07:15** - _Saron Yitbarek_

Kenneth Cukier给我们讲了一个简短的故事来说明这种新数据思维方式的力量。微软的一些研究人员开始考虑胰腺癌问题。

**07:27** - _Saron Yitbarek_

人们发现胰腺癌往往为时已晚，早期发现可以挽救生命。因此，研究人员开始询问在这些患者开始搜索有关胰腺癌的信息之前，在过去的几个月中他们在搜索什么？ 在前几年搜索了什么。

**07:46** - _Saron Yitbarek_

研究人员开始寻找埋藏在所有搜索数据中的线索。他们开始寻找模式。

**07:54** - _Kenneth Cukier_

他们有了重大发现。他们发现，在人们开始搜索胰腺癌的那一刻之前，他们可以识别搜索词中的模式，从而可以非常准确地预测人们患有胰腺癌。

**08:09** - _Kenneth Cukier_

这里的教训是，通过利用他们在数据内部潜在知识方面的想象力，他们可以挽救生命。他们现在所要做的就是找到一种方法，通过方法来解释这一发现，这样当人们在搜索这些术语时，他们可以以一种微妙的方式干预，说，“你可能要去医疗诊所检查一下。”

**08:29** - _Kenneth Cukier_

如果他们开始这样做，人们的生命将得到挽救。

**08:37** - _Saron Yitbarek_

研究人员偶然发现了一种新的癌症筛查方式，这种方法可以在一个月前提醒患者。利用数据不仅仅是一个利润或效率最大化的问题。

**08:52** - _Saron Yitbarek_

它的意义远不止于此。在所有这些数据中，隐藏着对人类真实的、巨大的积极意义。如果我们不使用这些数据，我们可能在欺骗自己。我们下一步要关注的是做好如何将数据投入工作的持久战。

**09:18** - _Saron Yitbarek_

哈佛医学院波士顿儿童医院去年进行了26000多例手术。进行约25万人次的儿童放射检查。

**09:31** - _Saron Yitbarek_

医护人员正在努力工作，但有一个巨大的障碍挡在他们面前。

**09:37** - _Ellen Grant_

在医院的环境中，尤其是作为医生，我们遇到的很多问题就是如何获取数据。

**09:45** - _Saron Yitbarek_

那是Ellen Grant医生 她是波士顿儿童医院的小儿神经放射科医生 她依靠访问数据和分析医学图像。

**09:56** - _Ellen Grant_

除非你设置了一个环境，否则要想进入存储图像的存档做额外的数据分析并不简单。当你在一个只提供标准医院电脑的阅览室里时，要做到这一点并不容易。

**10:14** - _Ellen Grant_

实际获取数据是有障碍的。

**10:17** - _Saron Yitbarek_

事实上，是因为医院负担不起存储数据的费用而丢弃了大量数据。所以，这些数据就这样丢失了。像Grant医生这样的放射科医生可能是第一批感受到数据过载受挫的医生。

**10:33** - _Saron Yitbarek_

当他们走向数字化后，他们开始创造大量的数据，这很快就使得数据变得无法处理。

**10:41** - _Ellen Grant_

作为临床医生的我，在阅览室里希望能够在研究环境中进行所有想要的分析。但没有办法轻易地从包中取走图像，拿到一些可以进行分析的地方，再拿到我手里。

**10:59** - _Saron Yitbarek_

顺便说一句，包就是医院存储其图像的数据库。Grant医生知道有一些工具可以让这些图像包发挥更大的功能，但成本太高。

**11:12** - _Ellen Grant_

随着我们进入机器学习和人工智能的时代，更多的事情会发生，我们需要这些更大的计算资源来真正开始做我们想做的大型数据库分析。

**11:27** - _Saron Yitbarek_

数据一直在堆积，但处理量不大。内部数据处理将遥不可及。而复杂、昂贵的超级计算机不是医院的选择。

**11:41** - _Saron Yitbarek_

Grant医生非常沮丧。

**11:44** - _Ellen Grant_

我们能不能想出一个更好的办法，让我把数据拿到这里来，分析一下，然后再拿回来，这样我就可以在领事那里完成，我在那里解释临床图像，因为我想把数据放在那里，并在那里快速分析。

**11:56** - _Ellen Grant_

我不想把数据移动到不同的电脑，再所有的代码都背下来，这不是我的工作。我的工作是试图理解非常复杂的医学疾病，并把所有这些事实真相记在脑子里。

**12:10** - _Ellen Grant_

我想把我的重点放在我的技术领域，但利用计算方面的新兴技术，而不必深入研究它。

**12:21** - _Saron Yitbarek_

Grant医生和世界各地的放射科医生需要的是一种点击图像、运行详细分析的方法，并让这一切都发生在云端，这样医院就不必建立自己的服务器场地，也不必把医务人员变成程序员。

**12:40** - _Saron Yitbarek_

他们需要一种使他们的数据尽可能地拯救生命的方法，因此，这正是Grant医生和几个代码英雄决定去做的。

**12:55** - _Saron Yitbarek_

Grant医生在波士顿儿童医院的团队与红帽和马萨诸塞州开放云（MOC）合作。稍后再谈MOC。首先，医院的生物医学工程师鲁道夫·皮纳尔，描述了他们的解决方案。它是一个开源的、基于容器的成像平台。

**13:15** - _Saron Yitbarek_

这也都是在云端运行的。所以你不受医院本身计算能力的限制。他们称自己的创作为ChRIS。

**13:24** - _Rudolph Pienaar_

ChRIS有一个后台数据库，其实就是一个Django Python机器，它可以跟踪用户。它可以跟踪处理过的数据。它可以跟踪结果。

**13:35** - _Rudolph Pienaar_

然后围绕这个数据库有一大堆的服务系统群，这些服务都是作为自己的实例存在于容器中。它们处理与医院资源的通信，比如与医院数据库通信。他们从这些资源中提取复杂的数据，将其推送到存在于云端或另一个实验室或其他任何地方的其他服务处理。在计算数据的地方，有这些服务，比如Kubernetes，时间表，你要做的数据的实际分析。然后，再把处理完的结果传送回来。

**14:11** - _Saron Yitbarek_

对于Grant医生来说，ChRIS成像平台是一种让数据活起来的方法。更重要的是，这种数据处理方式让她成为更好的医生。

**14:21** - _Ellen Grant_

医生的优秀，取决于他们一生的从业经验。如果我能把这一点融入到数据分析中，并获得更多的信息，我们就知道得更多，能够更好地结合这些信息。

**14:39** - _Ellen Grant_

例如，我对某些患者群体的某种伤害模式有什么样的认识，取决于根据我经验构造的知识体系。

**14:52** - _Ellen Grant_

实际上我现在可以根据真实数据创建他们分布的概率图，并通知每个人，或者我可以寻找有相似模式的相似患者，并告诉他们在接受治疗时，什么对他们最有效，以便更接近精准医疗。

**15:10** - _Ellen Grant_

整合大量的数据，并尝试探索我们过去的知识，并尽你所能以最好的方式告知如何对待任何人。

**15:21** - _Saron Yitbarek_

这对被送到医院的孩子意味着什么？Grant医生说，ChRIS平台能提供更有针对性的诊断和更个性化的护理。

**15:31** - _Ellen Grant_

如果我们有更复杂的数据库，我们可以更好地理解复杂的信息相互作用，并希望能更好地指导每个患者。我认为ChRIS基本上是我进入超级大脑入口，这比我自己更聪明，因为我不能一次把所有这些数据保存在我的大脑中。

**15:53** - _Saron Yitbarek_

当赌注这么大的时候，我们要突破人类大脑的极限。这是Máirín Duffy。她是红帽团队中的设计师，使ChRIS得以实现，她从个人经验中知道其中的利害关系。

**16:15** - _Máirín Duffy_

我父亲中风了，我一直在病人家属那里等待医疗技术诊断，因为当有人中风时，他们会把你送到医院，他们必须弄清楚是哪种类型的中风。根据类型，有不同的治疗方法。

**16:31** - _Máirín Duffy_

如果给出了错误的治疗方案，那么就会发生真正糟糕的事情。所以，在这种情况下，你能越快地把病人送来做核磁共振，就能越快地得到治疗方案。速度越快就有可能挽救他们的生命。

**16:43** - _Máirín Duffy_

想想看，仅仅是把图像处理从云端推送出来，并行化处理，就能让它快很多。因此，这个过程不是几个小时或几天，而是几分钟。

**16:55** - _Saron Yitbarek_

医学可能正迎来一个新的转折点。不是由药理学驱动，而是由计算机科学驱动。另外，想想像ChRIS这种东西的拓展性。

**17:08** - _Saron Yitbarek_

你可以让发展中国家的医生受益于波士顿儿童医院的专业知识和数据集。任何有手机服务的人都可以访问基于网络的计算和数据，从而挽救生命。

**17:24** - _Saron Yitbarek_

除了医学，很多其他领域也可能出现类似的拐点。但前提是，他们要想出如何让自己的数据找到隐藏信息。要做到这一点，他们需要发现一个全新的计算领域。

**17:46** - _Saron Yitbarek_

在世界各地，我们都在学习如何利用我们的数据。就像在波士顿儿童医院一样，找到数据中和我们目标相关的信息。

**17:56** - _Saron Yitbarek_

换句话说，我们正在处理这些数据。但我们之所以能做到这一点，是因为新一代的云计算使这些数据处理成为可能。

**18:11** - _Saron Yitbarek_

对于像ChRIS这样的平台来说，一个关键的因素是基于云计算的新型存储方式。请记住，很多医院都会把收集到的数据扔掉，因为他们真的无法保存所有的数据。

**18:25** - _Saron Yitbarek_

这就是我想重点讨论的数据洪流的最后一块拼图。存储解决方案。对于ChRIS来说，存储解决方案是以一个叫Ceph的开源项目的形式出现的。ChRIS使用的马萨诸塞州开放云，就基于Ceph。

**18:45** - _Saron Yitbarek_

所以，我和Ceph的创建者Sage Weil聊了聊，想了解更多关于像波士顿儿童医院这样的地方是如何在闪电般的时间内处理海量数据的。以下是我与Sage的对话。我认为第一个重要问题是什么是Ceph，它能做什么？

**19:05** - _Sage Weil_

当然，Ceph是一种软件定义的存储系统，它允许你提供可靠的存储服务，并在不可靠的硬件上提供各种协议。

**19:14** - _Sage Weil_

它的设计从开始就是满足可扩展性，所以你可以拥有非常非常大的存储系统，非常大的数据集，你可以让它们可用，并容忍硬件故障和网络故障等，而不影响可用性。

**19:29** - _Saron Yitbarek_

现在，数据太多了。

**19:31** - _Sage Weil_

是的。

**19:33** - _Saron Yitbarek_

如此大的工作量。要处理的东西实在是太多了。你觉得它的时机是需要解决方案的一部分吗？

**19:39** - _Sage Weil_

是的，当然。在当时，这个行业的巨大差距是显而易见的。没有开源的解决方案去解决可扩展的存储问题。所以很明显，我们需要建造一些东西。

**19:53** - _Saron Yitbarek_

当我们在思考我们每天要处理的数据量，以及它只会越来越多，只会越来越大，越来越难管理的事实时，你看到今天有哪些工作可以或许解决这种日益增长的需求？

**20:09** - _Sage Weil_

我认为有几方面的。第一件事是，当然有惊人的数据量正在产生，所以你需要可扩展的系统，它不仅可以在你存储的硬件和数据量上进行扩展，而且还有一种固定或几乎固定的操作开销。

**20:25** - _Saron Yitbarek_

嗯哼（肯定）。

**20:26** - _Sage Weil_

你不会想仅为每10PB存储空间或类似的东西就给别人付钱吧？我想他们必须是可操作的可扩展的。

**20:33** - _Saron Yitbarek_

是的。

**20:35** - _Sage Weil_

这是其中的一部分。我认为，人们与存储交互的方式也在改变。一开始，都是文件存储，然后我们有了虚拟机的块存储，我觉得对象存储在某种程度上是行业的重要趋势。

**20:51** - _Sage Weil_

我认为下一个阶段的目标并不是提供一个对象存储端点并能够在一个集群中存储数据，而是真正提高这种级别并拥有集群，地理上分布的云足迹或私有数据中心足迹网格，其中存储数据，并能够管理分布在这些足迹上的数据。

**21:13** - _Sage Weil_

也许你现在将数据写入一个位置，随着时间的推移，你把数据分层到其他位置，因为它更便宜、更近、或者因为数据更老，而且出于定价原因，您需要将其移动到性能更低、容量更大的层。

**21:27** - _Sage Weil_

处理诸如法规遵从性这样的事情，当您在欧洲的一个地方接收数据时，它必须保持在特定的政治边界内，才能遵守法规。

**21:39** - _Sage Weil_

在某些行业，像HIPAA这样的东西，限制了数据的移动方式。我认为，随着现代IT组织越来越多地分布在许多不同的数据中心和许多公共云以及他们自己的私有云基础设施上，能够管理所有这些数据并使这种管理自动化正变得越来越重要。

**21:58** - _Saron Yitbarek_

当你想到未来我们要如何管理和存储数据，以及未来如何处理数据的时候，开源在其中扮演了怎样的角色？你曾提到，你之所以要创建一个开源的解决方案，是因为你个人的理念和你对自由和开放软件的强烈感情。

**22:16** - _Saron Yitbarek_

你认为开源对未来其他解决方案有何影响？

**22:21** - _Sage Weil_

我认为，特别是在基础设施领域，解决方案正在向开源靠拢。我认为原因是基础设施领域的成本压力很大，特别是对于构建软件即服务或云服务的人来说，保持基础设施非常便宜很重要，从他们的角度来看，开源显然是一个非常好的方法。

**22:48** - _Sage Weil_

我认为第二个原因更多的是社会原因，在这个快速发展的领域里，你有新的工具、新的框架、新的协议、新的思维数据的方式，在这个领域有很多的创新和变化，有这么多不同的产品和项目在相互作用，所以很难以一种基于像你和不同的公司有合作协议和共同开发或任何东西的传统模式方式做到这一点。

**23:20** - _Sage Weil_

开源可以消除所有的摩擦。

**23:28** - _Saron Yitbarek_

Sage Weil是红帽公司的高级咨询工程师，也是Ceph项目的负责人。我将回到《经济学人》的Kenneth Cukier，以便我们可以进行一点缩小，因为我希望我们记住他关于我们与数据关系的那个看法，以及我们如何从泥板到印刷机再到像Sage打造的云端奇迹的进展。

**23:55** - _Kenneth Cukier_

这关乎人类的进步，关乎我们如何更好地理解世界和世界的实证，以改善世界。这也是人类一直以来的进步使命。

**24:08** - _Saron Yitbarek_

使命永远不会结束。但是，与此同时，学会处理我们收集到的数据并将其投入使用，这是整整一代人的开源任务。我们将在田纳西州的橡树岭国家实验室（Oak Ridge National Laboratory）短暂停留，结束我们的数据之旅。它是世界上最快的超级计算机Summit的所在地，或者至少是在2018年最快的超级计算机。

**24:43** - _Saron Yitbarek_

这台机器每秒要处理20万亿次计算。如果你要计算的话，那就是200 petaflops。这样的处理速度，对于医院、银行或者今天所有受益于高性能计算的成千上万的组织来说并不实用。

**25:04** - _Saron Yitbarek_

像Summit这样的超级计算机更多的是留给强子对撞机的领域。不过话说回来，我们曾经在泥板上记录的只是100字节的信息。

**25:16** - _Saron Yitbarek_

在数据存储和数据处理的故事中，非凡的壮举不断成为新的常态。有一天，我们的口袋里可能都有Summit级别的超级计算机。想一想，到时候我们将能够搜索到的答案。

**25:42** - _Saron Yitbarek_

下一集，我们聊聊无服务器。还是我们？第7集讲述我们与基于云的开发之间不断发展的关系。我们正在弄清楚我们的工作有多少可以抽象化，以及在这个过程中我们可能会放弃什么。

**25:58** - _Saron Yitbarek_

同时，如果你想深入了ChRIS的故事，请访问[redhat.com/chris](https://www.redhat.com/chris) 了解它是如何构建的，以及如何为项目本身做出贡献。

**26:12** - _Saron Yitbarek_

《代码英雄》是一款红帽公司原创的播客。在苹果播客，谷歌播客或任何您做事的地方免费收听。

**26:24** - _Saron Yitbarek_

我是 Saron Yitbarek。下次之前，继续编码。

--------------------------------------------------------------------------------

via: https://www.redhat.com/en/command-line-heroes/season-2/the-data-explosion

作者：[Red Hat][a]
选题：[bestony][b]
译者：[TimeBear](https://github.com/TimeBear)
校对：[校对者ID](https://github.com/校对者ID)

本文由 [LCRH](https://github.com/LCTT/LCRH) 原创编译，[Linux中国](https://linux.cn/) 荣誉推出
[a]: https://www.redhat.com/en/command-line-heroes
[b]: https://github.com/bestony
